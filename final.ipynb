{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suspicious Email Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Text Preprocessing\n",
    "\n",
    "Email text preprocessing is the process of cleaning and transforming raw email text data into a format that is suitable for analysis or machine learning tasks. The goal is to extract meaningful information, reduce noise, and standardize the text. Here are some of the key email text preprocessing steps:\n",
    "\n",
    "1. **Lowercasing:**\n",
    "2. **Removing Stopwords:**\n",
    "3. **Lemmatization:**  \n",
    "4. **Handling Missing Values:**\n",
    "   \n",
    "\n",
    "The combination of these preprocessing steps results in a clean and standardized representation of email text data, suitable for various natural language processing (NLP) tasks or machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        X = X.apply(self.clean_text)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "        text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "        return text\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.dropna()\n",
    "    features = df[['Email Text']].copy()\n",
    "    preprocessor = TextPreprocessor()\n",
    "    features['Email Text'] = preprocessor.fit_transform(features['Email Text'])\n",
    "    return features, df['Email Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "We split our preprocessed data into two main subsets:\n",
    "\n",
    "### Training Set\n",
    "The training set is used to train our machine learning models. It consists of a portion of the preprocessed data on which the models learn to recognize patterns and make predictions. During training, the models adjust their parameters based on the features in the training set to minimize the difference between predicted and actual outcomes.\n",
    "\n",
    "### Testing Set\n",
    "The testing set is reserved for evaluating the models' performance. It contains data that the models have not seen during training. By making predictions on the testing set, we can assess how well the models generalize to new, unseen email text.\n",
    "\n",
    "## Evaluation Metrics\n",
    "Common evaluation metrics include accuracy, precision, recall, and F1 score. These metrics provide insights into different aspects of the model's performance, such as how often it makes correct predictions and how well it identifies relevant instances.\n",
    "## Split Ratio\n",
    "We typically follow a common split ratio, allocating approximately 80% of the preprocessed data to the training set and 20% to the testing set. Adjusting the split ratio may be necessary depending on the dataset size and specific requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb_model(X_train, y_train):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train_vectorized, y_train)\n",
    "    return nb_model, vectorizer\n",
    "\n",
    "def train_rf_model(X_train, y_train):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_vectorized, y_train)\n",
    "    return rf_model, vectorizer\n",
    "\n",
    "def train_svm_model(X_train, y_train):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    svm_model = SVC(probability=True)\n",
    "    svm_model.fit(X_train_vectorized, y_train)\n",
    "    return svm_model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, df):\n",
    "    y_pred = model.predict(X_test)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='Phishing Email')  # Calculate Precision\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='Phishing Email')  # Calculate F1 score\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=df['Email Type'].unique(), yticklabels=df['Email Type'].unique())\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Phishing_Email.csv\"\n",
    "df = load_dataset(file_path)\n",
    "\n",
    "X, y = preprocess_data(df)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Email Type', data=df)\n",
    "plt.title('Distribution of Email Types')\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['Email Text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (NB)\n",
    "\n",
    "Naive Bayes is a probabilistic machine learning algorithm widely used for classifying emails, especially in the context of phishing detection. It calculates the probability that an email belongs to a particular class (phishing or not) based on the occurrence of specific words and features. Despite its \"naive\" assumption of feature independence, Naive Bayes performs well in detecting phishing emails due to its efficiency in handling high-dimensional data and fast training speeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model, nb_vectorizer = train_nb_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Model Evaluation:\")\n",
    "nb_accuracy, nb_precision, nb_f1, nb_roc_auc = evaluate_model(nb_model, nb_vectorizer.transform(X_test), y_test, df)\n",
    "print(\"ROC-AUC:\", nb_roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (RF)\n",
    "\n",
    "Random Forest is a robust ensemble learning algorithm that excels in classifying phishing emails. By constructing multiple decision trees during training and combining their predictions, Random Forest can effectively capture complex patterns and relationships in email text. Its ability to handle overfitting and its versatility make it a suitable choice for phishing email detection, where the model needs to generalize well to unseen instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model, rf_vectorizer = train_rf_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "rf_accuracy, rf_precision, rf_f1, rf_roc_auc = evaluate_model(rf_model, rf_vectorizer.transform(X_test), y_test, df)\n",
    "print(\"ROC-AUC:\", rf_roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "Support Vector Machine (SVM) is a powerful classification algorithm known for its effectiveness in identifying patterns in data. When applied to phishing email detection, SVM seeks an optimal hyperplane to separate phishing emails from legitimate ones. This method proves beneficial in scenarios where the relationships between features are intricate. SVM's ability to find optimal decision boundaries makes it well-suited for the nuanced patterns often found in phishing email content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model, svm_vectorizer = train_svm_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSVM Model Evaluation:\")\n",
    "svm_accuracy, svm_precision, svm_f1, svm_roc_auc = evaluate_model(svm_model, svm_vectorizer.transform(X_test), y_test, df)\n",
    "print(\"ROC-AUC:\", svm_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassifier Comparison:\\n\")\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"\\nNaive Bayes Precision:\", nb_precision)\n",
    "print(\"Random Forest Precision:\", rf_precision)\n",
    "print(\"SVM Precision:\", svm_precision)\n",
    "print(\"\\nNaive Bayes F1 Score:\", nb_f1)\n",
    "print(\"Random Forest F1 Score:\", rf_f1)\n",
    "print(\"SVM F1 Score:\", svm_f1)\n",
    "print(\"\\nNaive Bayes ROC-AUC:\", nb_roc_auc)\n",
    "print(\"Random Forest ROC-AUC:\", rf_roc_auc)\n",
    "print(\"SVM ROC-AUC:\", svm_roc_auc)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "classifiers = ['Naive Bayes', 'Random Forest', 'SVM']\n",
    "accuracy_values = [nb_accuracy, rf_accuracy, svm_accuracy]\n",
    "precision_values = [nb_precision, rf_precision, svm_precision]\n",
    "f1_values = [nb_f1, rf_f1, svm_f1]\n",
    "roc_auc_values = [nb_roc_auc, rf_roc_auc, svm_roc_auc]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "width = 0.4\n",
    "x = np.arange(len(classifiers))\n",
    "bars = ax.bar(x, accuracy_values, width=width, label='Accuracy')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classifiers)\n",
    "ax.legend()\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.show()\n",
    "\n",
    "ax.plot(classifiers, precision_values, marker='o', label='Precision')\n",
    "ax.plot(classifiers, f1_values, marker='o', label='F1-Score')\n",
    "\n",
    "for i, value in enumerate(precision_values):\n",
    "    plt.text(i, value + 0.01, f'{round(value, 3)}', ha='center', va='bottom', color='blue')\n",
    "\n",
    "for i, value in enumerate(f1_values):\n",
    "    plt.text(i, value - 0.01, f'{round(value, 3)}', ha='center', va='top', color='orange')\n",
    "\n",
    "ax.legend()\n",
    "plt.title('Precision and F1-Score Comparison')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(classifiers, roc_auc_values, marker='o', label='ROC-AUC')\n",
    "\n",
    "for i, value in enumerate(roc_auc_values):\n",
    "    plt.text(i, value + 0.01, round(value, 3), ha='center', va='bottom')\n",
    "\n",
    "ax.legend()\n",
    "plt.title('ROC-AUC Comparison')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this analysis, we applied three different classifiers (Naive Bayes, Random Forest, and Support Vector Machine) to detect phishing emails using a dataset loaded from \"Phishing_Email.csv\". The dataset was preprocessed, split into training and testing sets, and each classifier was trained using the training set. The trained models were then used to make predictions on the testing set.\n",
    "\n",
    "## Metric Prediction\n",
    "\n",
    "- **Accuracy:** Random Forest performed the best with an accuracy of 97.02%.\n",
    "- **Precision:** Naive Bayes had the highest precision, indicating a low rate of false positives.\n",
    "- **F1 Score:** Random Forest achieved the highest F1 score, balancing precision and recall effectively.\n",
    "- **ROC-AUC:** Random Forest also excelled in ROC-AUC, indicating strong overall performance.\n",
    "\n",
    "## Recommendations:\n",
    "\n",
    "- Random Forest is recommended for its balanced performance across multiple metrics.\n",
    "- Naive Bayes is a suitable alternative with high precision and overall good performance.\n",
    "- SVM shows limitations, especially in terms of F1 score, suggesting challenges in balancing precision and recall for phishing email detection.\n",
    "\n",
    "This report provides insights into the strengths and weaknesses of each model, guiding the choice of the most suitable classifier for the specific task of phishing email detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"left\" style=\"font-family: 'Arial', sans-serif; color: #66a3ff; text-shadow: 1px 1px 2px #004080;\">\n",
    "\n",
    "# Submitted by -\n",
    "Ananya Thakur 21052225  \n",
    "Tanmay Pandey 21052231  \n",
    "CSE 12\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
